{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics\n",
    "\n",
    "## Introduction to PyTorch\n",
    "\n",
    "### What is PyTorch?\n",
    "\n",
    "[PyTorch](https://pytorch.org/get-started/locally/) is a popular open-source deep learning framework known for its flexibility and ease of use. It's widely adopted in both research and industry for tasks ranging from simple machine learning models to complex neural networks.\n",
    "\n",
    "### Why PyTorch?\n",
    "\n",
    "- Dynamic computation graph: PyTorch's ability to dynamically build the computation graph at runtime makes it intuitive and easy to debug.\n",
    "- Strong community support and integration with Python: PyTorch is Pythonic and integrates well with the Python data science stack.\n",
    "- GPU acceleration: PyTorch makes it easy to move tensors to and from GPUs (supports Apple's Metal and Nvidia GPUs), which is crucial for training large models efficiently.\n",
    "\n",
    "## Tensors in PyTorch\n",
    "\n",
    "### What is a Tensor?\n",
    "\n",
    "Tensors are the fundamental data structures in PyTorch, similar to NumPy arrays but with the added capability of being used on a GPU.\n",
    "\n",
    "### Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[0.6560, 0.0980, 0.8618],\n",
      "        [0.1586, 0.7411, 0.3848]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a tensor from a list\n",
    "tensor_a = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(tensor_a)\n",
    "\n",
    "# Creating a tensor with random values\n",
    "tensor_b = torch.rand((2, 3))  # A 2x3 matrix of random numbers\n",
    "print(tensor_b)\n",
    "\n",
    "# Creating a tensor with zeros\n",
    "tensor_c = torch.zeros((3, 3))  # A 3x3 matrix of zeros\n",
    "print(tensor_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Tensor Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6560, 0.0980],\n",
      "        [0.8618, 0.1586],\n",
      "        [0.7411, 0.3848]])\n",
      "tensor([2., 4., 6.])\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping a tensor\n",
    "tensor_reshaped = tensor_b.view(3, 2)  # Reshape to 3x2\n",
    "print(tensor_reshaped)\n",
    "\n",
    "# Tensor addition\n",
    "tensor_sum = tensor_a + tensor_a\n",
    "print(tensor_sum)\n",
    "\n",
    "# Indexing\n",
    "print(tensor_a[1])  # Access the second element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu\n",
      "tensor([1., 2., 3.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eviofekeze/anaconda3/envs/snowEx/lib/python3.10/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Moving a tensor to GPU\n",
    "\n",
    "# Check which device is available\n",
    "available_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Available device: {available_device}\")\n",
    "\n",
    "tensor_a_gpu = tensor_a.to(available_device)\n",
    "print(tensor_a_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: Automatic Differentiation\n",
    "\n",
    "- PyTorch’s autograd system automatically calculates gradients, which are essential for training neural networks.\n",
    "- Every operation on tensors keeps track of the computation history, allowing PyTorch to backpropagate errors automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with gradient tracking enabled\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Perform a computation\n",
    "y = x ** 2 + 2* x ** 3\n",
    "\n",
    "# Backpropagate to compute the gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient\n",
    "print(x.grad)  # Should output 28.0, the derivative of x^2 + 2x^3 at x=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = x^2 + 2x^3$$\n",
    "$$y = 2x + 6x^2$$\n",
    "$$y = 2(2) + 6 \\times(2)^2$$\n",
    "$$y = 4 + (6 \\times 4)$$\n",
    "$$y = 4 + 2 $$\n",
    "$$y = 28 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "This example shows how PyTorch automatically calculates the gradient of a tensor operation, which is essential for updating the weights during training.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders\n",
    "\n",
    "### What is a Dataset in PyTorch?\n",
    "\n",
    "* Purpose: The `Dataset` class in PyTorch serves as an abstraction that allows you to manage, preprocess, and access your data in a consistent way.\n",
    "\n",
    "* Key Features:\n",
    "    - Handles how data is stored and accessed.\n",
    "    - Allows for custom data transformations and preprocessing.\n",
    "    - Integrates seamlessly with PyTorch’s `DataLoader` for efficient batching and shuffling.\n",
    "\n",
    "### What is a DataLoader in PyTorch?\n",
    "\n",
    "* Purpose: The `DataLoader` is an iterable that abstracts the complexity of handling data in batches, shuffling, and parallel loading.\n",
    "\n",
    "* Key Features:\n",
    "    - Efficiently loads data in mini-batches during training.\n",
    "    - Automatically shuffles data at the start of each epoch (if specified).\n",
    "    - Supports parallel data loading using multiple workers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the data sample and label at the specified index\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.config as config\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class InfrasoundDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class to create Infrasound dataset from audio file + annotation file\n",
    "    The Class applies the following functions\n",
    "    1. A Transformation specified in the configuration file, This can either be MFCC, Mel-Spectrgram or any added\n",
    "        in the future\n",
    "    2. A function to mix down audio to mono channel if more than on channel\n",
    "    3. A function to resample data to target sample rate specified in the config file\n",
    "    4. A function to pad the audio if sample is less that target sample\n",
    "    5. A function to trim sample\n",
    "\n",
    "    Args:\n",
    "        labels_file: path to file containing labels\n",
    "        waveform_file: path to file containing audio signals\n",
    "        transformation: features to be extracted from signal\n",
    "        target_sample_rate: the sample rate, defaults to 100Mhz\n",
    "        num_samples: size of chunks, each sec contains 100 samples\n",
    "        device: str: either of CPU or GPU\n",
    "\n",
    "    Returns:\n",
    "        signal: processed audio signal\n",
    "        label: resulting label\n",
    "    \"\"\"\n",
    "    labels_file: str\n",
    "    waveform_file: str\n",
    "    transformation: Any\n",
    "    target_sample_rate: int\n",
    "    num_samples: int\n",
    "    device: str = config.DEVICE\n",
    "    labels: Any = field(init=False)\n",
    "    waveform_raw: Any = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.labels = pd.read_parquet(self.labels_file)\n",
    "        self.waveform_raw = pd.read_parquet(self.waveform_file)\n",
    "        self.transformation = self.transformation.to(self.device)\n",
    "        logger.info(f\"Device in use: {self.device}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns: The len of processed data\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Function to process every input\n",
    "        Args:\n",
    "            index: index of input to be processed\n",
    "        Returns:\n",
    "            audio feature corresponding to the applied transformation\n",
    "        \"\"\"\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        signal = torch.tensor(np.array(self.waveform_raw.iloc[index]).reshape(1, 1000)).float()\n",
    "        _sr = config.SAMPLE_RATE\n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_not_target_sample_rate(signal, _sr)\n",
    "        signal = self._mix_down_if_not_mono(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        return signal, label\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            signal: Some audio signal\n",
    "        Returns:\n",
    "            truncated audio signal, to ensure all signals have the same len or num of samples\n",
    "        \"\"\"\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        \"\"\"\n",
    "        Pads signal if the length is shorter that the specified number of sample in the config file\n",
    "        Args:\n",
    "            signal: Some audio signal\n",
    "        Returns: Right padded audio\n",
    "        \"\"\"\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_not_target_sample_rate(self, signal, sr):\n",
    "        \"\"\"\n",
    "        Function to resample audio to sample target rate\n",
    "        Args:\n",
    "            signal: Some audio signal\n",
    "            sr: Sample rate from config file\n",
    "        Returns: resampled audio data\n",
    "        \"\"\"\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).to(self.device)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    @staticmethod\n",
    "    def _mix_down_if_not_mono(signal):\n",
    "        \"\"\"\n",
    "        Function to reduce audio to one/mono channel\n",
    "        Args:\n",
    "            signal: some audion data\n",
    "        Returns: mono channel audio\n",
    "        \"\"\"\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.labels.iloc[index, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining `__len__` and `__getitem__`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __len__: Returns the total number of samples in your dataset. PyTorch uses this method to know how many iterations to run during training.\n",
    "* __getitem__: Retrieves a specific sample from the dataset using its index. This method returns the data and its corresponding label, which PyTorch uses during training to form mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "tensor([[0.4963, 0.7682],\n",
      "        [0.0885, 0.1320],\n",
      "        [0.3074, 0.6341],\n",
      "        [0.4901, 0.8964],\n",
      "        [0.4556, 0.6323],\n",
      "        [0.3489, 0.4017]])\n",
      "\n",
      "Target:\n",
      "tensor([[0.0223],\n",
      "        [0.1689],\n",
      "        [0.2939],\n",
      "        [0.5185],\n",
      "        [0.6977],\n",
      "        [0.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Generate random data: 6 samples, each with 2 features\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "features = torch.rand(6, 2)\n",
    "\n",
    "# Generate random target values (e.g., for a regression problem)\n",
    "targets = torch.rand(6, 1)\n",
    "\n",
    "print(f\"Features:\\n{features}\")\n",
    "print(f\"\\nTarget:\\n{targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "========\n",
      "Data:\n",
      "tensor([[0.4556, 0.6323],\n",
      "        [0.4963, 0.7682]])\n",
      "Targets:\n",
      "tensor([[0.6977],\n",
      "        [0.0223]])\n",
      "\n",
      "Batch 2:\n",
      "========\n",
      "Data:\n",
      "tensor([[0.0885, 0.1320],\n",
      "        [0.3489, 0.4017]])\n",
      "Targets:\n",
      "tensor([[0.1689],\n",
      "        [0.8000]])\n",
      "\n",
      "Batch 3:\n",
      "========\n",
      "Data:\n",
      "tensor([[0.3074, 0.6341],\n",
      "        [0.4901, 0.8964]])\n",
      "Targets:\n",
      "tensor([[0.2939],\n",
      "        [0.5185]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "dataset = CustomDataset(data=features, targets=targets)\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Example of iterating through the DataLoader\n",
    "for idx, (batch_data, batch_labels) in enumerate(data_loader):\n",
    "    print(f\"Batch {idx+1}:\\n========\")\n",
    "    print(f\"Data:\\n{batch_data}\")\n",
    "    print(f\"Targets:\\n{batch_labels}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `shuffle=True` ensures that the data is shuffled at the beginning of each epoch, which helps prevent the model from learning patterns based on the order of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{dropdown} 🏋️ Exercise: What if we set `shuffle` to `False` and `batch_size` to 3?\n",
    "::::{tip}\n",
    "Check the Sample Size.\n",
    "::::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
